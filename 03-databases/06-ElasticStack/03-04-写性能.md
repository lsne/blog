
5. 写性能

```
客户端: 批量写: 建议一次 10m ~ 20m 之前
服务端:
refresh_interval: refresh间隔,默认1秒, -1表示不自动刷新,但index buffer满了也会刷新
indices.memory.index_buffer_size 静态参数, index buffer 大小, 建议10%
index.translog.durability 可以设置为 async, 然后设置下面的秒数
index.translog.sync_interval 设置需要的大小, 比如120s, 每120s写一次磁盘
index.translog.flush_threshold_size 默认512m, 即translog超过512m时会触发flush

设置副本为0, 写入完成后再增加

合理地设计shard数均匀分配在所有Node上

index.routing.allocation.total_shards_per_node 限定每个索引在每个Node上可分配的总主副分片数
```

6. 监控工具

```
安装:
./bin//elasticsearch-plugin install x-pack
或
./bin/kibana-plugin install x-pack

然后可以在kibana 上的  monitoring 查看
```

7. logstat

```
queue.type:persisted   #默认值为memory, 改为persisted磁盘存储, 性能大概下降5%
queue.max_bytes:4gb    #queue大小

线程相关:
pipeline.workers | -w    #线程数,即filter_output的处理线程数,默认是cpu核数
pipeline.batch.size| -b  #Batcher 一次批量获取的待处理文档数， 默认125， 如果是写入到es,文档大小*125 最好在10m~20m之间 （越大会占用越多的jvm heap空间, 可以通过jvm.option调整）
pipeline.batch.delay| -u #Batcher 等待的时长,单位为ms
```